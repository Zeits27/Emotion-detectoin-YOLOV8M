{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d4472f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T13:44:18.051502Z",
     "iopub.status.busy": "2025-09-13T13:44:18.051204Z",
     "iopub.status.idle": "2025-09-13T13:44:38.308610Z",
     "shell.execute_reply": "2025-09-13T13:44:38.307824Z",
     "shell.execute_reply.started": "2025-09-13T13:44:18.051471Z"
    },
    "papermill": {
     "duration": 22.822036,
     "end_time": "2025-09-08T15:18:56.819980",
     "exception": false,
     "start_time": "2025-09-08T15:18:33.997944",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Class distribution (original):\n",
      "  content: 788 images\n",
      "  happy: 776 images\n",
      "  fear: 838 images\n",
      "  sad: 824 images\n",
      "  disgust: 802 images\n",
      "  neutral: 863 images\n",
      "  surprise: 861 images\n",
      "  anger: 834 images\n",
      "Augmenting 394 images for class content\n",
      "Augmenting 388 images for class happy\n",
      "Augmenting 419 images for class fear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Argument(s) 'var_limit' are not valid for transform GaussNoise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 824 images for class sad\n",
      "Augmenting 401 images for class disgust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting 863 images for class neutral\n",
      "Augmenting 430 images for class surprise\n",
      "Augmenting 834 images for class anger\n",
      "✅ Done. Generated 4553 augmented samples.\n",
      "📂 Menyalin data asli ke folder augmented...\n",
      "✅ Data asli berhasil digabung dengan augmented dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "class EmotionAugmenter:\n",
    "    def __init__(self, dataset_multiplier=0.5):\n",
    "        self.dataset_multiplier = dataset_multiplier  # 0.5 = add 50% more data\n",
    "        self.class_names = ['anger', 'content', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "    def get_emotion_specific_augmentation(self, emotion_class):\n",
    "        base = [A.HorizontalFlip(p=0.5), A.Rotate(limit=10, p=0.6)]\n",
    "\n",
    "        if emotion_class in [0, 3, 6]:  # anger, fear, sad\n",
    "            specific = [\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=0.4),\n",
    "                A.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n",
    "            ]\n",
    "        elif emotion_class in [1, 4, 5]:  # content, happy, neutral\n",
    "            specific = [\n",
    "                A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.15, p=0.4),\n",
    "                A.GaussianBlur(blur_limit=(1, 3), p=0.2),\n",
    "            ]\n",
    "        else:  # disgust, surprise\n",
    "            specific = [\n",
    "                A.ElasticTransform(alpha=1, sigma=30, alpha_affine=30, p=0.3),\n",
    "                A.GridDistortion(num_steps=3, distort_limit=0.1, p=0.3),\n",
    "            ]\n",
    "\n",
    "        return A.Compose(base + specific, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    def augment_single_image(self, img_path, label_path, output_dir, aug_idx):\n",
    "        # 🔹 baca gambar dan konversi ke grayscale\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None or not os.path.exists(label_path):\n",
    "            return 0\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)  # tetap 3 channel untuk albumentations\n",
    "\n",
    "        bboxes, labels = [], []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    cls = int(float(parts[0]))\n",
    "                    bboxes.append(list(map(float, parts[1:5])))\n",
    "                    labels.append(cls)\n",
    "\n",
    "        if not bboxes:\n",
    "            return 0\n",
    "\n",
    "        dominant_emotion = max(set(labels), key=labels.count)\n",
    "        transform = self.get_emotion_specific_augmentation(dominant_emotion)\n",
    "\n",
    "        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        try:\n",
    "            aug = transform(image=image, bboxes=bboxes, class_labels=labels)\n",
    "            aug_img = aug['image']\n",
    "            aug_boxes = aug['bboxes']\n",
    "            aug_labels = aug['class_labels']\n",
    "\n",
    "            if not aug_boxes:\n",
    "                return 0\n",
    "\n",
    "            img_out = os.path.join(output_dir, 'images', f\"{base_name}_aug{aug_idx}.jpg\")\n",
    "            lbl_out = os.path.join(output_dir, 'labels', f\"{base_name}_aug{aug_idx}.txt\")\n",
    "\n",
    "            cv2.imwrite(img_out, aug_img)\n",
    "            with open(lbl_out, 'w') as f:\n",
    "                for box, lbl in zip(aug_boxes, aug_labels):\n",
    "                    f.write(f\"{lbl} {' '.join(f'{x:.6f}' for x in box)}\\n\")\n",
    "            return 1\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def augment_dataset(self, input_dir, output_dir):\n",
    "        images = glob.glob(os.path.join(input_dir, 'images', '*.jpg'))\n",
    "        if not images:\n",
    "            print(\"No images found\")\n",
    "            return\n",
    "    \n",
    "        # Group images by dominant class\n",
    "        class_to_images = defaultdict(list)\n",
    "        for img in images:\n",
    "            base = os.path.splitext(os.path.basename(img))[0]\n",
    "            lbl = os.path.join(input_dir, 'labels', f\"{base}.txt\")\n",
    "            if not os.path.exists(lbl):\n",
    "                continue\n",
    "    \n",
    "            labels = []\n",
    "            with open(lbl, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        labels.append(int(float(parts[0])))\n",
    "    \n",
    "            if not labels:\n",
    "                continue\n",
    "    \n",
    "            dominant = max(set(labels), key=labels.count)\n",
    "            class_to_images[dominant].append((img, lbl))\n",
    "    \n",
    "        print(\"📊 Class distribution (original):\")\n",
    "        for cls, imgs in class_to_images.items():\n",
    "            print(f\"  {self.class_names[cls]}: {len(imgs)} images\")\n",
    "    \n",
    "        oversample_factors = {0: 1.0, 5: 1.0, 6: 1.0}  # contoh untuk weak classes\n",
    "    \n",
    "        total_generated = 0\n",
    "        for cls, img_list in class_to_images.items():\n",
    "            multiplier = oversample_factors.get(cls, 0.5)\n",
    "            n_to_aug = int(len(img_list) * multiplier)\n",
    "            if n_to_aug == 0:\n",
    "                print(f\"Skipping augmentation for {self.class_names[cls]}\")\n",
    "                continue\n",
    "    \n",
    "            chosen = random.sample(img_list, min(len(img_list), n_to_aug))\n",
    "            print(f\"Augmenting {n_to_aug} images for class {self.class_names[cls]}\")\n",
    "    \n",
    "            for idx, (img, lbl) in enumerate(chosen):\n",
    "                total_generated += self.augment_single_image(img, lbl, output_dir, idx)\n",
    "    \n",
    "        print(f\"✅ Done. Generated {total_generated} augmented samples.\")\n",
    "        \n",
    "        # 🔹 copy data asli ke output_dir\n",
    "        print(\"📂 Menyalin data asli ke folder augmented...\")\n",
    "        os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "\n",
    "        for img in images:\n",
    "            base = os.path.splitext(os.path.basename(img))[0]\n",
    "            lbl = os.path.join(input_dir, 'labels', f\"{base}.txt\")\n",
    "\n",
    "            out_img = os.path.join(output_dir, 'images', f\"{base}.jpg\")\n",
    "            out_lbl = os.path.join(output_dir, 'labels', f\"{base}.txt\")\n",
    "\n",
    "            shutil.copy(img, out_img)\n",
    "            if os.path.exists(lbl):\n",
    "                shutil.copy(lbl, out_lbl)\n",
    "\n",
    "        print(\"✅ Data asli berhasil digabung dengan augmented dataset\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    augmenter = EmotionAugmenter()\n",
    "    augmenter.augment_dataset(\n",
    "        input_dir=\"/kaggle/working/Human-face-emotions-28/train\",\n",
    "        output_dir=\"/kaggle/working/augmented_emotion_train\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c001ec01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T13:45:07.066233Z",
     "iopub.status.busy": "2025-09-13T13:45:07.065853Z",
     "iopub.status.idle": "2025-09-13T13:45:07.705005Z",
     "shell.execute_reply": "2025-09-13T13:45:07.704385Z",
     "shell.execute_reply.started": "2025-09-13T13:45:07.066213Z"
    },
    "papermill": {
     "duration": 0.677331,
     "end_time": "2025-09-08T15:18:57.523144",
     "exception": false,
     "start_time": "2025-09-08T15:18:56.845813",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11139 label files\n",
      "✅ Cleaning selesai. 4553 file sudah diperbaiki.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path folder label\n",
    "labels_path = \"/kaggle/working/augmented_emotion_train/labels\"\n",
    "label_files = glob.glob(os.path.join(labels_path, \"*.txt\"))\n",
    "\n",
    "print(f\"Found {len(label_files)} label files\")\n",
    "\n",
    "fixed = 0\n",
    "for file in label_files:\n",
    "    new_lines = []\n",
    "    changed = False\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                try:\n",
    "                    # Konversi class id dari float ke int\n",
    "                    cls_id = str(int(float(parts[0])))\n",
    "                    rest = parts[1:]\n",
    "                    new_line = \" \".join([cls_id] + rest)\n",
    "                    new_lines.append(new_line)\n",
    "                    \n",
    "                    # Kalau aslinya beda (misal \"5.0\" jadi \"5\"), tandai sudah diubah\n",
    "                    if parts[0] != cls_id:\n",
    "                        changed = True\n",
    "                except ValueError:\n",
    "                    print(f\"⚠️  Error parsing line in {file}: {line.strip()}\")\n",
    "            else:\n",
    "                # Simpan line apa adanya (misalnya kosong / invalid)\n",
    "                new_lines.append(line.strip())\n",
    "    \n",
    "    # Tulis balik file kalau ada perubahan\n",
    "    if changed:\n",
    "        with open(file, \"w\") as f:\n",
    "            f.write(\"\\n\".join(new_lines) + \"\\n\")\n",
    "        fixed += 1\n",
    "\n",
    "print(f\"✅ Cleaning selesai. {fixed} file sudah diperbaiki.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e1d420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T13:45:26.999940Z",
     "iopub.status.busy": "2025-09-13T13:45:26.999369Z",
     "iopub.status.idle": "2025-09-13T13:45:27.004833Z",
     "shell.execute_reply": "2025-09-13T13:45:27.004065Z",
     "shell.execute_reply.started": "2025-09-13T13:45:26.999914Z"
    },
    "papermill": {
     "duration": 0.036333,
     "end_time": "2025-09-08T15:19:01.013760",
     "exception": false,
     "start_time": "2025-09-08T15:19:00.977427",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data.yaml written to /kaggle/working/augmented_emotion_train/data.yaml\n"
     ]
    }
   ],
   "source": [
    "data_yaml_path = \"/kaggle/working/augmented_emotion_train/data.yaml\"\n",
    "\n",
    "yaml_content = \"\"\"path: /kaggle/working/augmented_emotion_train\n",
    "\n",
    "train: images\n",
    "val: /kaggle/working/Human-face-emotions-28/valid/images\n",
    "test:  /kaggle/working/Human-face-emotions-28/test/images\n",
    "nc: 8\n",
    "names: ['anger','content','disgust','fear','happy','neutral','sad','surprise']\n",
    "\"\"\"\n",
    "\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"✅ data.yaml written to\", data_yaml_path)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8202609,
     "sourceId": 12960736,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8213053,
     "sourceId": 12976210,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8213066,
     "sourceId": 12976226,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25156.934736,
   "end_time": "2025-09-08T22:16:07.060518",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-08T15:16:50.125782",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
